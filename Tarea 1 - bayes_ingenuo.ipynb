{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 1: Bayes ingenuo\n",
    "\n",
    "Este programa clasifica correos electrónicos como spam o ham utilizando el alrogítmo de bayes ingenuo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "usePackage <- function(p) \n",
    "{\n",
    "  if (!is.element(p, installed.packages()[,1]))\n",
    "    install.packages(p, repos = \"https://cran.itam.mx/\")\n",
    "  suppressPackageStartupMessages(require(p, character.only = TRUE, quietly  = TRUE))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "usePackage('R.utils')\n",
    "usePackage('tm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga los datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "download.mails <- function(url, dir_name, file_name){\n",
    "\n",
    "  if (!file.exists(dir_name)) {\n",
    "    dir.create(dir_name)  #El directorio se crea donde este corriendo en Notebook\n",
    "  }\n",
    "  \n",
    "    # destfile es como nombramos nuestro archivo\n",
    "    #file.path va a poner un \\ entre dir_name y el file_name\n",
    "  download.file(url, destfile=file.path(dir_name, paste0(file_name,\".tar.bz2\")) )\n",
    "    # Ahora lo vamos a descompactar\n",
    "  bunzip2(file.path(dir_name, paste0(file_name,\".tar.bz2\")))\n",
    "    # Quita el formato tar, saca todo de un archivo y lo pone en varios\n",
    "    # Todo lo que explote va a quedar dentro de dir_name\n",
    "  untar(file.path(dir_name, paste0(file_name,\".tar\")), exdir = dir_name)\n",
    "    # Este paso es por limpieza, quitamos el comprimido\n",
    "  if (file.exists(file.path(dir_name, paste0(file_name,\".tar\")))) {\n",
    "    file.remove(file.path(dir_name, paste0(file_name,\".tar\")))\n",
    "  }\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_name <- \"data\"\n",
    "file_name <- \"easy_ham_2\"\n",
    "url <- \"http://spamassassin.apache.org/old/publiccorpus/20030228_easy_ham_2.tar.bz2\"\n",
    "\n",
    "download.mails(url, dir_name, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url <- \"http://spamassassin.apache.org/old/publiccorpus/20030228_hard_ham.tar.bz2\"\n",
    "file_name <- \"hard_ham\"\n",
    "\n",
    "download.mails(url, dir_name, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url <- \"http://spamassassin.apache.org/old/publiccorpus/20030228_spam_2.tar.bz2\"\n",
    "file_name <- \"spam_2\"\n",
    "\n",
    "download.mails(url, dir_name, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de los correos electrónicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos una función que lea el mensaje del archivo que se le pase como parámetro\n",
    "# asumimos que el archivo contiene un correo\n",
    "\n",
    "lee_mensaje <- function(correo) {\n",
    "  fd <- file(correo, open = \"rt\") #Abre el archivo\n",
    "  lineas <- readLines(fd, warn=FALSE)  #Leemos el archivo, es un vector de caracteres\n",
    "  close(fd) #cierro el archivo\n",
    "    #Ahora vamos a buscar la primer linea en blanco, pues despues de esta empieza el correo\n",
    "    # lineas == \"\" va a regresar un vector de booleanos con TRUE y FALSE\n",
    "    #Con which pides que te traiga los indices del vector donde hay TRUE\n",
    "    # which(lineas == \"\")[1] + 1 a partir de esta linea ya es el cuerpo del correo\n",
    "  mensaje <- lineas[seq(which(lineas == \"\")[1] + 1, length(lineas), 1)]\n",
    "  return (paste(mensaje, collapse = \"\\n\")) #Colapsa el vector de caracteres para tener un unico texto\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos variables con los directorios donde se encuentran los datos\n",
    "trayectoria_spam     <- file.path(dir_name, \"spam_2\")\n",
    "trayectoria_easyham  <- file.path(dir_name, \"easy_ham_2\")\n",
    "trayectoria_hardham  <- file.path(dir_name, \"hard_ham\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPAM: dividimos la base de datos en training y testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Leemos el directorio donde se encuentran los correos clasificados como spam\n",
    "archivos_correos_spam <- dir(trayectoria_spam) #dir me regresa el contenido del directorio\n",
    "#Se genera un vector con los nombres de todos los archivos\n",
    "\n",
    "# quitamos el guión llamado cmds\n",
    "archivos_correos_spam <- archivos_correos_spam[which(archivos_correos_spam!=\"cmds\")] #[1:250]\n",
    "\n",
    "#### Hacemos la división de la base tomando primero un sample ####\n",
    "sample_spam<-sample(archivos_correos_spam)\n",
    "\n",
    "archivos_correos_spam_training<-sample_spam[1:1000]  #Los primeros 1000 mails barajeados se usaran para training\n",
    "archivos_correos_spam_testing<-tail(sample_spam,length(sample_spam)-1000) #El resto de los mails se utilizaran para testing\n",
    "\n",
    "todo_spam <- sapply(archivos_correos_spam_training, #Obtenemos todo_spam con la base de entrenamiento\n",
    "                   function(p) lee_mensaje(file.path(trayectoria_spam, p)))\n",
    "                    \n",
    "todo_spam <- enc2utf8(todo_spam) #Cambias la coddificacion a utf8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy ham: dividimos la base de datos en training y testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el directorio donde se encuentran los correos clasificados como ham fácilmente identificables\n",
    "archivos_correos_easy_ham <- dir(trayectoria_easyham)\n",
    "\n",
    "# quitamos el guión llamado cmds\n",
    "archivos_correos_easy_ham <- archivos_correos_easy_ham[which(archivos_correos_easy_ham!=\"cmds\")] #[1:250]\n",
    "\n",
    "### Hacemos la división de la base tomando primero un sample ####\n",
    "sample_easyHam<-sample(archivos_correos_easy_ham)\n",
    "\n",
    "archivos_correos_easy_ham_training<-sample_easyHam[1:1000] #Los primeros 1000 mails barajeados se usaran para training\n",
    "archivos_correos_easy_ham_testing<-tail(sample_easyHam,length(sample_easyHam)-1000) #El resto de los mails se utilizaran para testing\n",
    "\n",
    "todo_easy_ham <- sapply(archivos_correos_easy_ham_training,\n",
    "                    function(p) lee_mensaje(file.path(trayectoria_easyham, p)))\n",
    "\n",
    "todo_easy_ham <- enc2utf8(todo_easy_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de corpus y bolsa de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "obtiene_TermDocumentMatrix <- function (vector_correos) {\n",
    "  control <- list(stopwords = TRUE, # Palabras presentes en todas partes: de, y, etc\n",
    "                removePunctuation = TRUE, \n",
    "                removeNumbers = TRUE,\n",
    "                minDocFreq = 2) #Que deje las palabras que por lo menos aparezcan dos veces\n",
    "    #VectorSource le dices que es un vector que es la fuente del corpus\n",
    "    #Creamos un objeto de tipo corpus con la funcion Corpus\n",
    "  corpus <- Corpus(VectorSource(vector_correos))\n",
    "  return(TermDocumentMatrix(corpus, control))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_TDM <- obtiene_TermDocumentMatrix(todo_spam) #Es un objeto de tipo TermDocumentMatrix\n",
    "\n",
    "# Crea un data frame que provee el conjunto de caracteristicas de los datos de entrenamiento SPAM\n",
    "matriz_spam <- as.matrix(spam_TDM) #Aqui se tiene la matriz: en renglones palabras, en columnas archivo\n",
    "\n",
    "conteos_spam <- rowSums(matriz_spam)\n",
    "df_spam <- data.frame(cbind(names(conteos_spam),\n",
    "                            as.numeric(conteos_spam)),\n",
    "                      stringsAsFactors = FALSE)\n",
    "names(df_spam) <- c(\"terminos\", \"frecuencia\")\n",
    "df_spam$frecuencia <- as.numeric(df_spam$frecuencia)\n",
    "ocurrencias_spam <- sapply(1:nrow(matriz_spam),\n",
    "                          function(i) # Obtiene la proporcion de documentos que contiene cada palabra\n",
    "                          {\n",
    "                            length(which(matriz_spam[i, ] > 0)) / ncol(matriz_spam)\n",
    "                          })\n",
    "\n",
    "# Vamos a obtener la proba de que salga cada palabra de manera frecuentista\n",
    "densidad_spam <- df_spam$frecuencia/sum(df_spam$frecuencia,na.rm = TRUE)\n",
    "\n",
    "df_spam <- transform(df_spam,  #Agrego columnas de densidad y ocurrencias al df\n",
    "                     densidad = densidad_spam,\n",
    "                     ocurrencias = ocurrencias_spam)\n",
    "\n",
    "# IMPORTANTE: densidad es la proba de que x palabra aparezca en spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_ham_TDM <- obtiene_TermDocumentMatrix(todo_easy_ham)\n",
    "\n",
    "# Crea un data frame que provee el conjunto de caracteristicas de los datos de entrenamiento easy ham\n",
    "matriz_easy_ham <- as.matrix(easy_ham_TDM)\n",
    "\n",
    "conteos_easy_ham <- rowSums(matriz_easy_ham)\n",
    "df_easy_ham <- data.frame(cbind(names(conteos_easy_ham),\n",
    "                            as.numeric(conteos_easy_ham)),\n",
    "                      stringsAsFactors = FALSE)\n",
    "names(df_easy_ham) <- c(\"terminos\", \"frecuencia\")\n",
    "df_easy_ham$frecuencia <- as.numeric(df_easy_ham$frecuencia)\n",
    "ocurrencias_easy_ham <- sapply(1:nrow(matriz_easy_ham),\n",
    "                           function(i) # Obtiene la proporcion de documentos que contiene cada palabra\n",
    "                           {\n",
    "                             length(which(matriz_easy_ham[i, ] > 0)) / ncol(matriz_easy_ham)\n",
    "                           })\n",
    "densidad_easy_ham <- df_easy_ham$frecuencia/sum(df_easy_ham$frecuencia,na.rm = TRUE)\n",
    "\n",
    "df_easy_ham <- transform(df_easy_ham,\n",
    "                     densidad = densidad_easy_ham,\n",
    "                     ocurrencias = ocurrencias_easy_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo de probabilidad a posteriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Bayes ingenuo te dice que multipliques las probas, pero para cada palabra, estas son muy pequeñas\n",
    "# Tendriamos una proba muy cercana a cero, pues la precision de la compu no es tan grande\n",
    "# Si sumamos las probas no hay problema, porque los numeros no se haran mas pequeños (como en la mult)\n",
    "# Hay que pasarlo a logaritmo para poder hacer sumas las multiplicaciones\n",
    "\n",
    "# Por omision a priori=0.5, es decir, proba de que sea spam es 0.5\n",
    "# La c representa el caso en el que haya una palabra que no se encuentre en nuestra base de entrenamiento\n",
    "# no la podemos hacer cero porque anularia todo, pero le damos un valor pequeño. \n",
    "a_posteriori <- function(trayectoria, df_entrenamiento, a_priori = 0.5, c = 1e-6)\n",
    "{\n",
    "  mensaje <- lee_mensaje(trayectoria)\n",
    "  mensaje <- enc2utf8(mensaje)\n",
    "  mensaje_TDM <- obtiene_TermDocumentMatrix(mensaje)\n",
    "  conteos_mensaje <- rowSums(as.matrix(mensaje_TDM))\n",
    "\n",
    "  # Encuentra palabras en data frame de entrenamiento\n",
    "    #Palabras en comun del correo y la base\n",
    "  mensaje_palabras_comunes <- intersect(names(conteos_mensaje), df_entrenamiento$terminos)\n",
    "  \n",
    "  # Ahora sólo aplicamos la clasificación Bayes ingenuo\n",
    "  if(length(mensaje_palabras_comunes) < 1) #ninguna palabra en comun\n",
    "  {\n",
    "    #return(a_priori * c ^ (length(conteos_mensaje)))\n",
    "    return(log(a_priori) + (length(conteos_mensaje)) *log(c)) #Aqui aplicamos el logaritmo\n",
    "  }\n",
    "  else\n",
    "  {  #match da los indices de las palabras que si empatan\n",
    "    probabilidades_palabras_comunes <- df_entrenamiento$densidad[match(mensaje_palabras_comunes, df_entrenamiento$terminos)]\n",
    "    #return(a_priori * prod(probabilidades_palabras_comunes) * c ^ (length(conteos_mensaje) - length(mensaje_palabras_comunes)))\n",
    "    return(log(a_priori) + sum(log(probabilidades_palabras_comunes)) + log(c) * (length(conteos_mensaje) - length(mensaje_palabras_comunes)))\n",
    "  }\n",
    "}\n",
    "\n",
    "#Nota que como por la formula de BI te interesa el maximo, no hay problema en regresar el logaritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasifica_spam <- function(trayectoria, archivos) {\n",
    "\n",
    "  hard_ham_spam_prueba <- sapply(archivos,\n",
    "                             function(p) a_posteriori(file.path(trayectoria, p), df_entrenamiento = df_spam))\n",
    "  hard_ham_ham_prueba <- sapply(archivos,\n",
    "                            function(p) a_posteriori(file.path(trayectoria, p), df_entrenamiento = df_easy_ham))\n",
    "  \n",
    "  return (ifelse(hard_ham_spam_prueba > hard_ham_ham_prueba,\n",
    "                        TRUE,\n",
    "                        FALSE))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard ham: dividimos la base de datos en training y testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el directorio donde se encuentran los correos clasificados como ham dificlmente identificables\n",
    "archivos_correos_hard_ham <- dir(trayectoria_hardham)\n",
    "\n",
    "# quitamos el guión llamado cmds\n",
    "archivos_correos_hard_ham <- archivos_correos_hard_ham[which(archivos_correos_hard_ham!=\"cmds\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_ham_res <- clasifica_spam(trayectoria_hardham, archivos_correos_hard_ham)\n",
    "easy_ham_res <- clasifica_spam(trayectoria_easyham, archivos_correos_easy_ham_testing) #Clasificamos con la base testing\n",
    "spam_res     <- clasifica_spam(trayectoria_spam,    archivos_correos_spam_testing) # Clasificamos con la base testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Mode   FALSE    TRUE \n",
       "logical     398       2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "   Mode   FALSE    TRUE \n",
       "logical      21     376 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "   Mode   FALSE    TRUE \n",
       "logical     115     135 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(easy_ham_res)\n",
    "summary(spam_res)\n",
    "summary(hard_ham_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tipo de mail  | Resultados SIN dividir la base de datos                  |Resultados dividiendo la base de datos\n",
    "------------- | ---------------------------------------------------------|-----------------------------------------------------\n",
    "Easy Ham      | FALSE: 1399 / TRUE: 1                                    | FALSE: 398 / TRUE: 2\n",
    "Spam          | FALSE: 21 / TRUE: 1376                                   | FALSE: 21 / TRUE: 376\n",
    "Hard Ham      | FALSE: 116 / TRUE: 134                                   | FALSE: 115 / TRUE: 135"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El cambio que se puede notar, tanto en Easy Ham como en Spam, es muy notorio y redundante: las respectivas cantidades de su correcta clasificación difieren en mil correos, mismos que fueron empleados en la base de entrenamiento. Dada esta obervación, se puede afirmar plenamente que el modelo sí se puede generalizar y aún así se siguen obteniendo muy buenos resultados para esta base de datos. Claro, este experimento quedá un poco limitado ya que únicamente se ha probado con un conjunto de mails. Una forma de seguir explorando la eficacia del método, sería alimentando al programa con nuevos mails.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
